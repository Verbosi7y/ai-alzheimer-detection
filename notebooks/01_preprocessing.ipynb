{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade pip\n",
    "%pip install numpy\n",
    "%pip install matplotlib\n",
    "%pip install seaborn\n",
    "%pip install scikit-image\n",
    "%pip install scikit-learn\n",
    "%pip install imbalanced-learn\n",
    "%pip install albumentations\n",
    "%pip install opencv-python\n",
    "%pip install pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from skimage import io\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "import albumentations as aug\n",
    "import cv2\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directory to Kaggle's Alzheimer MRI Preprocessed Dataset. Link: https://www.kaggle.com/datasets/sachinkumar413/alzheimer-mri-dataset\n",
    "\n",
    "Alzheimer's Disease Dementia Classes: Non Demented, Very Mild Demented, Mild Demented, Moderate Demented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENTER PARENT PATH - Example: C:\\Users\\{USERNAME}\\alzheimer-project-ai4all\n",
    "parent_path = r\"ENTER PARENT PATH\"\n",
    "\n",
    "kaggle_dir = r\"assets\\Kaggle\\alzheimer_mri_preprocessed_dataset\"\n",
    "kaggle_path = os.path.join(parent_path, kaggle_dir)\n",
    "\n",
    "classes = [\"Non_Demented\", \"Very_Mild_Demented\", \"Mild_Demented\", \"Moderate_Demented\"]\n",
    "encoded_classes = {status: idx for idx, status in enumerate(classes)}\n",
    "\n",
    "# add parent to path\n",
    "sys.path.append(parent_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading images and labels (classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(kaggle_path, classes):\n",
    "    x_img, y_label = [], []\n",
    "    for class_name in classes:\n",
    "        class_path = os.path.join(kaggle_path, class_name)\n",
    "\n",
    "        for image_filename in os.listdir(class_path):\n",
    "            img = io.imread(os.path.join(class_path, image_filename), as_gray=True)\n",
    "            x_img.append(img)\n",
    "            # 0 = Non Demented, 1 = Very Mild Demented, 2 = Mild Demented, 3 = Moderate Demented\n",
    "            y_label.append(classes.index(class_name))\n",
    "    \n",
    "    return np.array(x_img), np.array(y_label)\n",
    "\n",
    "x, y = load_images(kaggle_path, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into 90% training and 10% testing data. Ensure same class distribution using stratify=y (class/label)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.9 * len(x))\n",
    "test_size = len(x) - train_size\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,  y, test_size=0.1, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the overall sizes and verify the split occured correctly for each classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Size: \", train_size)\n",
    "print(\"Test Size: \", test_size)\n",
    "\n",
    "print(encoded_classes)\n",
    "\n",
    "unique = np.unique(y, return_counts=True)\n",
    "size = unique[1].tolist()\n",
    "\n",
    "print(\"Original: \", unique)\n",
    "\n",
    "unique = np.unique(y_train, return_counts=True)\n",
    "size = unique[1].tolist()\n",
    "\n",
    "print(\"Split: \", unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(image, output_dir):\n",
    "    image = Image.fromarray(image)\n",
    "    image.save(output_dir, format=\"PNG\")\n",
    "\n",
    "for class_dir in classes:\n",
    "    resampled_dir = fr\"assets\\Kaggle\\alzheimer_mri_preprocessed_dataset\\Test_Data\\{class_dir}\"\n",
    "    output_path = f\"{parent_path}\\{resampled_dir}\"\n",
    "\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "\n",
    "for i, (image, label) in enumerate(zip(x_test, y_test)):\n",
    "    test_dir = fr\"assets\\Kaggle\\alzheimer_mri_preprocessed_dataset\\Test_Data\\{classes[label]}\\{i}.png\"\n",
    "    output_path = os.path.join(parent_path, test_dir)\n",
    "    save_image(image, output_path)\n",
    "\n",
    "test_dir = fr\"assets\\Kaggle\\alzheimer_mri_preprocessed_dataset\\Test_Data\\test_data.npz\"\n",
    "output_path = os.path.join(parent_path, test_dir)\n",
    "np.savez_compressed(output_path, images=x_test, labels=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stats.statistics import Statistics\n",
    "\n",
    "title = \"AD Classification Distribution with Training Dataset\"\n",
    "\n",
    "unique = np.unique(y_train, return_counts=True)\n",
    "size = unique[1].tolist()\n",
    "\n",
    "sample_dist = (classes, size)\n",
    "\n",
    "print(encoded_classes)\n",
    "print(unique)\n",
    "Statistics.pieChartClassificationPlot(sample_dist, title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To further balance the dataset, we need to employ more techniques. One of which is data augmentation.\n",
    "Method to balance the data augmentation process is to define class-specific augmentation rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from alzheimersdetection.Dataset import AlzheimerDataset\n",
    "\n",
    "data_transforms = aug.Compose(\n",
    "    [\n",
    "        aug.Resize(height=128, width=128),\n",
    "        aug.HorizontalFlip(p=0.5),\n",
    "        aug.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=0, border_mode=cv2.BORDER_CONSTANT, value=0, p=1),\n",
    "        aug.RandomBrightnessContrast(brightness_limit=0.0, contrast_limit=0.4, p=1)\n",
    "    ]\n",
    ")\n",
    "\n",
    "x_aug, y_aug = [], []\n",
    "rates = [1, 1, 2, 10]\n",
    "\n",
    "# Function to augment\n",
    "def augment(image, transform):\n",
    "    augmented_image = transform(image=np.array(image))[\"image\"]  # Extract augmented image from Albumentations output\n",
    "    return augmented_image\n",
    "\n",
    "for i, (image, label) in enumerate(zip(x_train, y_train)):\n",
    "    transform_dir = f\"transformed\\\\{classes[label]}\\\\og-{i}.png\"\n",
    "    output_path = os.path.join(parent_path, transform_dir)\n",
    "    # save_image(image, output_path)\n",
    "\n",
    "    for j in range(rates[label]):\n",
    "        transform_dir = f\"transformed\\\\{classes[label]}\\\\{i}-{j}.png\"\n",
    "        output_path = os.path.join(parent_path, transform_dir)\n",
    "        augment_image = augment(image, data_transforms)\n",
    "        # save_image(augment_image, output_path)\n",
    "        x_aug.append(augment_image)\n",
    "        y_aug.append(label)\n",
    "\n",
    "x_aug = np.array(x_aug)\n",
    "y_aug = np.array(y_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.concatenate((x_train, x_aug), axis=0)\n",
    "y_train = np.concatenate((y_train, y_aug), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class Distribution after Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"AD Classification Distribution after Data Augmentation\"\n",
    "\n",
    "unique = np.unique(y_train, return_counts=True)\n",
    "size = unique[1].tolist()\n",
    "\n",
    "sample_dist = (classes, size)\n",
    "\n",
    "print(encoded_classes)\n",
    "print(unique)\n",
    "Statistics.pieChartClassificationPlot(sample_dist, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io.imshow(x_train[1])\n",
    "print(\"Shape Before:\", x_train.shape)\n",
    "\n",
    "# Preprocess data (normalize pixel values)\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "x_train = scaler.fit_transform(x_train.reshape(-1, x_train.shape[1] * x_train.shape[2]))  # Reshape for normalization\n",
    "\n",
    "print(\"Shape After: \", x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is still imbalanced and to fix this, we need to increase the minority class's representation (oversampling). This allows us to have a more balanced dataset.\n",
    "\n",
    "We will be using Adaptive Synthetic Sampling (ADASYN) to oversample the minority classes.\n",
    "\n",
    "Optimal Results: ~25% distribution across all AD classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"AD Classification Distribution before Oversampling\")\n",
    "class_counts = Counter(y_train)\n",
    "print(class_counts)\n",
    "\n",
    "# Visualize class imbalance before oversampling\n",
    "plt.bar(class_counts.keys(), class_counts.values())\n",
    "plt.xlabel(\"Class Label\")\n",
    "plt.ylabel(\"Number of Images\")\n",
    "plt.title(\"Class Distribution Before Oversampling\")\n",
    "plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10 # This is the k-neighbors which will be used for ADASYN\n",
    "\n",
    "adasyn = ADASYN(n_neighbors=k)\n",
    "\n",
    "x_resampled, y_resampled = adasyn.fit_resample(x_train, y_train)\n",
    "print(\"Original dataset shape counter: %s\" % Counter(y_resampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_resampled.shape)\n",
    "size = x_resampled.shape[0]\n",
    "X_resampled = x_resampled.reshape(size, 128, 128)\n",
    "\n",
    "# Invert normalization\n",
    "X_resampled = (X_resampled * 255).astype(np.uint8)  # Scale back to 0-255 and convert to uint8 for PyTorch\n",
    "\n",
    "print(X_resampled.shape)\n",
    "io.imshow(X_resampled[19612])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine original and synthetic data\n",
    "#X_balanced = np.concatenate((x, x_resample))\n",
    "#y_balanced = np.concatenate((y, y_resample))\n",
    "\n",
    "# Print class distribution after oversampling\n",
    "print(\"AD Classification Distribution after Oversampling\")\n",
    "#class_counts_balanced = Counter(y_balanced)\n",
    "class_counts_balanced = Counter(y_resampled)\n",
    "print(class_counts_balanced)\n",
    "\n",
    "print(x_resampled.shape)\n",
    "print(y_resampled.shape)\n",
    "\n",
    "# Visualize class distribution after oversampling\n",
    "plt.bar(class_counts_balanced.keys(), class_counts_balanced.values())\n",
    "plt.xlabel(\"Class Label\")\n",
    "plt.ylabel(\"Number of Images\")\n",
    "plt.title(\"Class Distribution After Oversampling (ADASYN)\")\n",
    "plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the Data onto a compressed Numpy Archive (*.npz)\n",
    "Image is saved for viewing purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_dir in classes:\n",
    "    resampled_dir = fr\"resampled\\{class_dir}\"\n",
    "    output_path = f\"{parent_path}\\{resampled_dir}\"\n",
    "\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "\n",
    "for i, (image, label) in enumerate(zip(X_resampled, y_resampled)):\n",
    "    resampled_dir = fr\"resampled\\{classes[label]}\\{i}.png\"\n",
    "    output_path = os.path.join(parent_path, resampled_dir)\n",
    "    og_image = Image.fromarray(image)\n",
    "    og_image.save(output_path, format=\"PNG\")\n",
    "\n",
    "resampled_dir = fr\"resampled\\augmented_adasyn_data.npz\"\n",
    "output_path = os.path.join(parent_path, resampled_dir)\n",
    "np.savez_compressed(output_path, images=X_resampled, labels=y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io.imshow(X_resampled[19612])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
